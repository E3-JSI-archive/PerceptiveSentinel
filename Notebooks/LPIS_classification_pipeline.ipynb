{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Parcel Identification System (LPIS) prediction for Slovenia\n",
    "\n",
    "This notebook shows the steps towards constructing machine learning model for LPIS prediction for Slovenia.\n",
    "\n",
    "### Overview\n",
    "\n",
    "#### Requirements\n",
    "1. Downloaded and processed Sentinel data *(relevant [notebook](https://github.com/sentinel-hub/eo-learn/blob/master/examples/land-cover-map/SI_LULC_pipeline.ipynb))*\n",
    "    * Sentinel-2 data download\n",
    "    * cloud detection and masking\n",
    "    * interpolation    \n",
    "    \n",
    "\n",
    "2. Downloaded and grouped LPIS data *(relevant [notebook](LPISDataFromGeopedija.ipynb))*\n",
    "    * LPIS data download\n",
    "    * LPIS class grouping \n",
    "    \n",
    "#### Samples construction\n",
    "1. Data sample construction\n",
    "    * edge mask construction\n",
    "    * oversampling\n",
    "2. Feature calculation\n",
    "    * stream feature calculation\n",
    "    * elevation\n",
    "    \n",
    "#### Feature selection and model construction\n",
    "1. Feature selection\n",
    "    * FASTENER\n",
    "2. Model construction\n",
    "    * data normalization\n",
    "    * model training\n",
    "    * model testing\n",
    "3. Model usage\n",
    "    * prediction of LPIS on chosen region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, some necessary imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from joblib import dump, load\n",
    "from sklearn import tree\n",
    "from collections import Counter\n",
    "\n",
    "# from eolearn.mask import EdgeExtractionTask\n",
    "# from eolearn.geometry import BalancedClassSampler, BalancedClassSamplerTask\n",
    "from notebook_temporary.edge_extraction import EdgeExtractionTask  # Change once it will be in develop\n",
    "from notebook_temporary.sampling import BalancedClassSampler, \\\n",
    "    BalancedClassSamplerTask  # Change once it will be in develop\n",
    "from notebook_temporary.temporal_features import ValeroWorkflow\n",
    "\n",
    "from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
    "    LoadTask, SaveTask, EOExecutor\n",
    "from eolearn.io import SentinelHubDemTask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples construction\n",
    "\n",
    "### Edge mask calculation\n",
    "When training the classifier we don't want to include the pixels on the borders of parcels. These pixels are potential mixed-class instances that can have a negative effect on the learning process. So prior to sampling we will construct an timeless mask which excludes the edges. This is already done in an EOTask so we just need to call it.\n",
    "\n",
    "Since we will be classificating crops we will calculate edges based on the NDVI metric and the green band. Along those, let's calculate all the metrics that we will be needing later which are the other base bands red, blue, NIR (Near infra red) and the vegetation related indices NIR, ARVI, EVI, NDVI, NDWI, SIPI and SAVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBaseFeatures(EOTask):\n",
    "\n",
    "    def __init__(self, c1=6, c2=7.5, L=1, Lvar=0.5, delta=10 ** -10):\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.L = L\n",
    "        self.Lvar = Lvar\n",
    "\n",
    "        # We add a small number that doesn't significantly change the result to avoid divisions by zero\n",
    "        self.delta = delta\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "        nir = eopatch.data['BANDS'][..., [7]]\n",
    "        blue = eopatch.data['BANDS'][..., [1]]\n",
    "        red = eopatch.data['BANDS'][..., [3]]\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NIR', nir)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'BLUE', blue)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'RED', red)\n",
    "\n",
    "        arvi = np.clip((nir - (2 * red) + blue) / (nir + (2 * red) + blue + self.delta), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'ARVI', arvi)\n",
    "\n",
    "        evi = np.clip(2.5 * ((nir - red) / (nir + (self.c1 * red) - (self.c2 * blue) + self.L + self.delta)), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'EVI', evi)\n",
    "\n",
    "        ndvi = np.clip((nir - red) / (nir + red + self.delta), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NDVI', ndvi)\n",
    "\n",
    "        ndwi = np.clip((blue - red) / (blue + red + self.delta), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NDWI', ndwi)\n",
    "\n",
    "        sipi = np.clip((nir - blue) / (nir - red + self.delta), 0, 2)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'SIPI', sipi)\n",
    "\n",
    "        savi = np.clip(((nir - red) / (nir + red + self.Lvar + self.delta)) * (1 + self.Lvar), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'SAVI', savi)\n",
    "\n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecefaea6c8074063b6e571c67082bced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base = AddBaseFeatures()\n",
    "edges = EdgeExtractionTask(features={FeatureType.DATA: ['NDVI', 'BLUE']})\n",
    "\n",
    "# This tutorial assumes all the patches are saved in current directory in folder patches. You can change this here\n",
    "patches_path = r'D:\\Users\\Beno\\PycharmProjects\\PerceptiveSentinel\\Notebooks\\test_folder'\n",
    "# save_patch_location = patches_path\n",
    "# save_path = f'{os.path.abspath(os.getcwd())}/patches_output'\n",
    "##### ijs team: sentinel patchi za tesirat: E:\\Data\\PerceptiveSentinel\\SVN_Interpolated2\n",
    "# save_path = patches_path\n",
    "save_path = patches_path + os.sep + \"out_patches\"\n",
    "load = LoadTask(patches_path)\n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)\n",
    "save = SaveTask(save_path, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "execution_args = []\n",
    "for name in next(os.walk(patches_path))[1]:\n",
    "    execution_args.append({\n",
    "        load: {'eopatch_folder': name},\n",
    "        save: {'eopatch_folder': name}\n",
    "    })\n",
    "\n",
    "workflow = LinearWorkflow(load,\n",
    "                          base,\n",
    "                          edges,\n",
    "                          save)\n",
    "\n",
    "executor = EOExecutor(workflow, execution_args)\n",
    "executor.run(multiprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2042e05091a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize the mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpatch_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0meopatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEOPatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{save_path}/{patch_name}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Visualize the mask\n",
    "\n",
    "patch_name = next(os.walk(save_path))[1][0]\n",
    "eopatch = EOPatch.load(f'{save_path}/{patch_name}')\n",
    "\n",
    "edges = eopatch.mask_timeless['EDGES_INV'].squeeze()\n",
    "img = np.clip(eopatch.data['BANDS'][10][..., [3, 2, 1]] * 3.5, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "We don't want to train a classifier on every point as earth observation data can be very large and thus unfeasible. In this step we will choose a sample of the area. The properties of a sample should be that it is taken from all region uniformly and because we are training a classifier we want to have each class represented equally. This can be done with the BalancedClassSampler task. We will also exclude the the edge regions we calculated before to have a \"clean\" sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: 4, 6: 16, 12: 90, 9: 92, 8: 97, 11: 104, 14: 120, 4: 149, 7: 518, 3: 722, 1: 3018, 13: 4494, 2: 5137, 0: 10689}\n",
      "{10: 26, 6: 80, 9: 92, 11: 104, 7: 518, 12: 668, 3: 722, 8: 756, 14: 871, 4: 931, 1: 3018, 13: 4494, 2: 5137, 0: 10689}\n",
      "    LPIS_2017_G2 patch_identifier    x    y\n",
      "0              0       test_patch  427  359\n",
      "1              0       test_patch  461  465\n",
      "2              0       test_patch  367  181\n",
      "3              0       test_patch  475  416\n",
      "4              0       test_patch  142  151\n",
      "..           ...              ...  ...  ...\n",
      "359           10       test_patch  477  196\n",
      "360           10       test_patch  477  199\n",
      "361           10       test_patch  478  200\n",
      "362           10       test_patch  479  201\n",
      "363           10       test_patch  476  200\n",
      "\n",
      "[364 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "class_feature = (FeatureType.MASK_TIMELESS, 'LPIS_2017_G2')\n",
    "sampler = BalancedClassSampler(class_feature=class_feature,\n",
    "                               valid_mask=(FeatureType.MASK_TIMELESS, 'EDGES_INV'),\n",
    "                               seed=seed)\n",
    "sampler.sample_folder(save_path, lazy_loading=True)\n",
    "distribution = sampler.get_prior_class_distribution()\n",
    "\n",
    "# sorting so we can easier see which classes are less represented\n",
    "distribution = {k: v for k, v in sorted(distribution.items(), key=lambda item: item[1])}\n",
    "\n",
    "# Lets display what was sampled\n",
    "print(distribution)\n",
    "\n",
    "# We can try to increase the smallest samples classes by sampling again and this time specifying which classes\n",
    "# are weak to do additional sampling around them once encountered\n",
    "sampler2 = BalancedClassSampler(class_feature=class_feature,\n",
    "                               valid_mask=(FeatureType.MASK_TIMELESS, 'EDGES_INV'),\n",
    "                               seed=seed,\n",
    "                               weak_classes=[10, 6, 12, 8, 14, 4])\n",
    "sampler2.sample_folder(save_path, lazy_loading=True)\n",
    "distribution2 = sampler2.get_prior_class_distribution()\n",
    "distribution2 = {k: v for k, v in sorted(distribution2.items(), key=lambda item: item[1])}\n",
    "print(distribution2)\n",
    "\n",
    "# Final samples\n",
    "samples = sampler2.get_balanced_data()\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream features calculation\n",
    "As we didn't have stream features calculated for all data we will now compute neccesary stream features for only the points that we decided on with sampling in previous step.\n",
    "We will also add height of the pixel as one of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_patch\n",
      "505 500\n"
     ]
    }
   ],
   "source": [
    "# Assumes all the patches have same shape\n",
    "\n",
    "\n",
    "# For each patch that contains any samples we will construct mask to specify where the stream\n",
    "# features are computer. We don't want to compute them for the whole patch as it would take a long time\n",
    "patches = next(os.walk(save_path))[1]\n",
    "\n",
    "# Separate points by patch. Patch identifier is by default it's folder name\n",
    "separated_by_patch = [(x, samples[samples['patch_identifier'] == x]) for x in patches]\n",
    "execution_args = []\n",
    "height = None\n",
    "width = None\n",
    "for name, points in separated_by_patch:\n",
    "    \n",
    "    print(name)\n",
    "    eopatch = EOPatch.load(f'{save_path}/{name}')\n",
    "    height, width, _ = eopatch[class_feature].shape\n",
    "    print(height, width)\n",
    "    #continue\n",
    "    stream_mask = np.zeros((height, width), dtype=bool)\n",
    "    for x, y in zip(points['x'], points['y']):\n",
    "        stream_mask[x, y] = True\n",
    "\n",
    "    eopatch.add_feature(FeatureType.MASK_TIMELESS, 'STREAM_VALID', stream_mask[..., np.newaxis])\n",
    "    eopatch.save(f'{save_path}/{name}', overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<FeatureType.DATA: 'data'>, 'ARVI')\n",
      "(<FeatureType.DATA: 'data'>, 'ARVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'EVI')\n",
      "(<FeatureType.DATA: 'data'>, 'EVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'NDVI')\n",
      "(<FeatureType.DATA: 'data'>, 'NDVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'NDWI')\n",
      "(<FeatureType.DATA: 'data'>, 'NDWI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'SIPI')\n",
      "(<FeatureType.DATA: 'data'>, 'SIPI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'SAVI')\n",
      "(<FeatureType.DATA: 'data'>, 'SAVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'BLUE')\n",
      "(<FeatureType.DATA: 'data'>, 'BLUE') 123\n",
      "(<FeatureType.DATA: 'data'>, 'GREEN')\n",
      "(<FeatureType.DATA: 'data'>, 'GREEN') 123\n",
      "(<FeatureType.DATA: 'data'>, 'RED')\n",
      "(<FeatureType.DATA: 'data'>, 'RED') 123\n",
      "(<FeatureType.DATA: 'data'>, 'NIR')\n",
      "(<FeatureType.DATA: 'data'>, 'NIR') 123\n",
      "test_patch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bd8193d795490f92d3b103b972eb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After rolling\n",
      "Derivative\n",
      "Finished\n",
      "After rolling\n",
      "Derivative\n",
      "Finished\n",
      "After rolling\n",
      "Derivative\n"
     ]
    }
   ],
   "source": [
    "###### TODO Filip\n",
    "# Za testirat lahko uporabiš te patche: E:\\Data\\PerceptiveSentinel\\SVN_Interpolated2\n",
    "# Skopiraj kodo ko bo v `notebook_temporary` folder\n",
    "\n",
    "base_features = [\"ARVI\", \"EVI\", \"NDVI\", \"NDWI\", \"SIPI\", \"SAVI\", \"BLUE\", \"RED\", \"NIR\"]\n",
    "tasks = [ValeroWorkflow(feature_name, valid_mask_feature=(FeatureType.MASK_TIMELESS, 'STREAM_VALID')) for feature_name in base_features]\n",
    "all_stream_feature_names = [n for s_task in tasks for n in s_task.feature_list()]  # 'NDVI_max_mean', 'NDVI_slope' .....\n",
    "##### TODO Filip\n",
    "load = LoadTask(save_path)\n",
    "save = SaveTask(save_path, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "execution_args = []\n",
    "for name in next(os.walk(save_path))[1]:\n",
    "    execution_args.append({\n",
    "        load: {'eopatch_folder': name},\n",
    "        save: {'eopatch_folder': name}\n",
    "    })\n",
    "    print(name)\n",
    "\n",
    "# This tasks adds elevation data to the patch\n",
    "dem = SentinelHubDemTask((FeatureType.DATA_TIMELESS, 'DEM'), size=(height, width))\n",
    "workflow = LinearWorkflow(load, \n",
    "                          #dem, \n",
    "                          *tasks, \n",
    "                          save\n",
    "                         )\n",
    "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
    "executor.run(multiprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the stream features are calculated we just need to put them into the format suitable for feature selection\n",
    "# we need to contruct a pandas DataFrame with column names of features and the class name. Each row represents a single point\n",
    "extended_samples = []\n",
    "for name, points in separated_by_patch:\n",
    "    eopatch = EOPatch.load(f'{save_path}/{name}', lazy_loading=True)\n",
    "    for x, y in zip(points['x'], points['y']):\n",
    "        point_data = [(class_feature[1], eopatch[class_feature][x, y, 0])] \\\n",
    "                     + [(f, eopatch.data_timeless[f][x, y].squeeze()) for f in all_stream_feature_names]\n",
    "        extended_samples.append(dict(point_data))\n",
    "extended_samples = pd.DataFrame(extended_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and model construction\n",
    "The features will be chosen using the FASTENER algorithm\n",
    "## TODO filip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = FASTENER(extended_samples) ###### TODO FILIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction\n",
    "Once we have final samples with selected only the best features we can train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6936154588018159\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "extended_samples = pd.read_csv('D:/Samples/review.csv')\n",
    "selected_features = ['DEM', 'ARVI_max_mean_len', 'BLUE_max_mean_surf', 'BLUE_mean_val', 'BLUE_neg_surf']\n",
    "model = tree.DecisionTreeClassifier()\n",
    "y = extended_samples['LPIS_2017'].to_numpy()\n",
    "x = extended_samples[selected_features].to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "labels = Counter(extended_samples['LPIS_2017']).keys()\n",
    "no_classes = range(len(labels))\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim(bottom=0.14, top=0)\n",
    "plot_confusion_matrix(model, x_test, y_test, labels=no_classes,\n",
    "                      display_labels=labels,\n",
    "                      cmap='viridis',\n",
    "                      include_values=False,\n",
    "                      xticks_rotation='vertical',\n",
    "                      normalize='pred',\n",
    "                      ax=ax)\n",
    "f1 = f1_score(y_test, y_pred, labels=no_classes, average='macro')\n",
    "print(f'f1: {f1}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model usage on a sample region\n",
    "All the features that we choose with FASTENER need to be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<FeatureType.DATA: 'data'>, 'ARVI')\n",
      "(<FeatureType.DATA: 'data'>, 'ARVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'EVI')\n",
      "(<FeatureType.DATA: 'data'>, 'EVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'NDVI')\n",
      "(<FeatureType.DATA: 'data'>, 'NDVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'NDWI')\n",
      "(<FeatureType.DATA: 'data'>, 'NDWI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'SIPI')\n",
      "(<FeatureType.DATA: 'data'>, 'SIPI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'SAVI')\n",
      "(<FeatureType.DATA: 'data'>, 'SAVI') 123\n",
      "(<FeatureType.DATA: 'data'>, 'BLUE')\n",
      "(<FeatureType.DATA: 'data'>, 'BLUE') 123\n",
      "(<FeatureType.DATA: 'data'>, 'GREEN')\n",
      "(<FeatureType.DATA: 'data'>, 'GREEN') 123\n",
      "(<FeatureType.DATA: 'data'>, 'RED')\n",
      "(<FeatureType.DATA: 'data'>, 'RED') 123\n",
      "(<FeatureType.DATA: 'data'>, 'NIR')\n",
      "(<FeatureType.DATA: 'data'>, 'NIR') 123\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4d4df4b18c58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msave\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveTask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meopatch_folder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatch_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite_permission\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOverwritePermission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOVERWRITE_PATCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m workflow = LinearWorkflow(load,\n\u001b[1;32m---> 13\u001b[1;33m                           \u001b[0mdem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                           \u001b[1;33m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                           save)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dem' is not defined"
     ]
    }
   ],
   "source": [
    "###### TODO Filip praktično isti klic kot zgoraj, samo da je maska IS_VALID namesto STREAM_VALID\n",
    "### ubistvu se kliče samo tiste, ki so potrebni, glede na to kar je vrnu FASTENER\n",
    "base_features = [\"ARVI\", \"EVI\", \"NDVI\", \"NDWI\", \"SIPI\", \"SAVI\", \"BLUE\", \"GREEN\", \"RED\", \"NIR\"]\n",
    "tasks = [ValeroWorkflow(feature_name) for feature_name in base_features]\n",
    "all_stream_feature_names = [n for s_task in tasks for n in s_task.feature_list()]  # 'NDVI_max_mean', 'NDVI_slope' .....\n",
    "\n",
    "##### TODO Filip\n",
    "\n",
    "patch_name = next(os.walk(patches_path))[1][0]\n",
    "load = LoadTask(patches, eopatch_folder=patch_name)\n",
    "save = SaveTask(patches, eopatch_folder=patch_name, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "workflow = LinearWorkflow(load,\n",
    "                          dem,\n",
    "                          *tasks,\n",
    "                          save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to arrange the features in the same way as we used to when training the model so they can be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch = EOPatch.load('D:/Users/Beno/PycharmProjects/PerceptiveSentinel/Notebooks/test_patch')\n",
    "\n",
    "t, width, height, _ = eopatch.data['BANDS'].shape\n",
    "\n",
    "x_patch = np.zeros((height * width, len(fastener_features)))\n",
    "i = 0\n",
    "for w in range(width):\n",
    "    for h in range(height):\n",
    "        x_patch[i] = [float(eopatch.data_timeless[f][w][h][0]) for f in fastener_features]\n",
    "        i += 1\n",
    "\n",
    "lpis = eopatch.mask_timeless['LPIS_2017'].squeeze()\n",
    "y_pred_patch = model.predict(x_patch)\n",
    "\n",
    "# reshape back to original shape\n",
    "img = np.reshape(y_pred_patch, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color scheme for coloring the classes and legend\n",
    "new_classes = {0: ('Not Farmland', 'xkcd:black'),\n",
    "               1: ('Grass', 'xkcd:brown'),\n",
    "               2: ('Maize', 'xkcd:butter'),\n",
    "               3: ('Orchards', 'xkcd:royal purple'),\n",
    "               4: ('Other', 'xkcd:white'),\n",
    "               5: ('Peas', 'xkcd:spring green'),\n",
    "               6: ('Potatoes', 'xkcd:poo'),\n",
    "               7: ('Pumpkins', 'xkcd:pumpkin'),\n",
    "               8: ('Soybean', 'xkcd:baby green'),\n",
    "               9: ('Summer cereals', 'xkcd:cool blue'),\n",
    "               10: ('Sun flower', 'xkcd:piss yellow'),\n",
    "               11: ('Vegetables', 'xkcd:bright pink'),\n",
    "               12: ('Vineyards', 'xkcd:grape'),\n",
    "               13: ('Winter cereals', 'xkcd:ice blue'),\n",
    "               14: ('Winter rape', 'xkcd:neon blue')}\n",
    "\n",
    "names = []\n",
    "boundaries = np.zeros(15)\n",
    "for i in range(15):\n",
    "    names.append(new_classes[i][1])\n",
    "    boundaries[i] = i - 0.5\n",
    "# colormap to color with specified colors\n",
    "cmap = matplotlib.colors.ListedColormap(names)\n",
    "# boundaries used for color map\n",
    "norm = colors.BoundaryNorm(boundaries, cmap.N, clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150, figsize=(12, 12))\n",
    "plt.title('Predicted')\n",
    "#add_legend(plt)\n",
    "plt.imshow(img, cmap=cmap, norm=norm)\n",
    "\n",
    "plt.figure(dpi=150, figsize=(12, 12))\n",
    "plt.title('LPIS_2017')\n",
    "#add_legend(plt)\n",
    "plt.imshow(lpis, cmap=cmap, norm=norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
