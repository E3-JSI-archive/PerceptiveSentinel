{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Parcel Identification System (LPIS) prediction for Slovenia\n",
    "\n",
    "This notebook shows the steps towards constructing machine learning model for LPIS prediction for Slovenia.\n",
    "\n",
    "### Overview\n",
    "\n",
    "#### Requirements\n",
    "1. Downloaded and processed Sentinel data *(relevant [notebook](https://github.com/sentinel-hub/eo-learn/blob/master/examples/land-cover-map/SI_LULC_pipeline.ipynb))*\n",
    "    * Sentinel-2 data download\n",
    "    * cloud detection and masking\n",
    "    * interpolation    \n",
    "    \n",
    "\n",
    "2. Downloaded and grouped LPIS data *(relevant [notebook](LPISDataFromGeopedija.ipynb))*\n",
    "    * LPIS data download\n",
    "    * LPIS class grouping \n",
    "    \n",
    "#### Samples construction\n",
    "1. Data sample construction\n",
    "    * edge mask construction\n",
    "    * oversampling\n",
    "2. Feature calculation\n",
    "    * stream feature calculation\n",
    "    * elevation\n",
    "    \n",
    "#### Feature selection and model construction\n",
    "1. Feature selection\n",
    "    * FASTENER\n",
    "2. Model construction\n",
    "    * data normalization\n",
    "    * model training\n",
    "    * model testing\n",
    "3. Model usage\n",
    "    * prediction of LPIS on chosen region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, some necessary imports\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from eolearn.mask import EdgeExtractionTask\n",
    "# from eolearn.geometry import BalancedClassSampler, BalancedClassSamplerTask\n",
    "from notebook_temporary.edge_extraction import EdgeExtractionTask  # Change once it will be in develop\n",
    "from notebook_temporary.sampling import BalancedClassSampler, \\\n",
    "    BalancedClassSamplerTask  # Change once it will be in develop\n",
    "\n",
    "from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
    "    LoadTask, SaveTask, EOExecutor\n",
    "from eolearn.io import SentinelHubDemTask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples construction\n",
    "\n",
    "### Edge mask calculation\n",
    "When training the classifier we don't want to include the pixels on the borders of parcels. These pixels are potential mixed-class instances that can have a negative effect on the learning process. So prior to sampling we will construct an timeless mask which excludes the edges. This is already done in an EOTask so we just need to call it.\n",
    "\n",
    "Since we will be classificating crops we will calculate edges based on the NDVI metric and the green band. Along those, let's calculate all the metrics that we will be needing later which are the other base bands red, blue, NIR (Near infra red) and the vegetation related indices NIR, ARVI, EVI, NDVI, NDWI, SIPI and SAVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBaseFeatures(EOTask):\n",
    "\n",
    "    def __init__(self, c1=6, c2=7.5, L=1, Lvar=0.5, delta=10 ** -10):\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.L = L\n",
    "        self.Lvar = Lvar\n",
    "\n",
    "        # We add a small number that doesn't significantly change the result to avoid divisions by zero\n",
    "        self.delta = delta\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "        nir = eopatch.data['BANDS'][..., [7]]\n",
    "        blue = eopatch.data['BANDS'][..., [1]]\n",
    "        red = eopatch.data['BANDS'][..., [3]]\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NIR', nir)\n",
    "\n",
    "        arvi = np.clip((nir - (2 * red) + blue) / (nir + (2 * red) + blue + self.delta), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'ARVI', arvi)\n",
    "\n",
    "        evi = np.clip(2.5 * ((nir - red) / (nir + (self.c1 * red) - (self.c2 * blue) + self.L + self.delta)), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'EVI', evi)\n",
    "\n",
    "        ndvi = np.clip((nir - red) / (nir + red + self.delta), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NDVI', ndvi)\n",
    "\n",
    "        ndwi = np.clip((blue - red) / (blue + red + self.delta), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'NDWI', ndwi)\n",
    "\n",
    "        sipi = np.clip((nir - blue) / (nir - red + self.delta), 0, 2)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'SIPI', sipi)\n",
    "\n",
    "        savi = np.clip(((nir - red) / (nir + red + self.Lvar + self.delta)) * (1 + self.Lvar), -1, 1)\n",
    "        eopatch.add_feature(FeatureType.DATA, 'SAVI', savi)\n",
    "\n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = AddBaseFeatures()\n",
    "edges = EdgeExtractionTask(features={FeatureType.DATA: ['NDVI', 'GREEN']})\n",
    "\n",
    "# This tutorial assumes all the patches are saved in current directory in folder patches. You can change this here\n",
    "patches_path = f'{os.path.abspath(os.getcwd())}/patches'\n",
    "# save_patch_location = patches_path\n",
    "# save_path = f'{os.path.abspath(os.getcwd())}/patches_output'\n",
    "save_path = patches_path\n",
    "load = LoadTask(patches_path)\n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)\n",
    "save = SaveTask(save_path, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "execution_args = []\n",
    "for name in next(os.walk(patches_path))[1]:\n",
    "    execution_args.append({\n",
    "        load: {'eopatch_folder': name},\n",
    "        save: {'eopatch_folder': name}\n",
    "    })\n",
    "\n",
    "workflow = LinearWorkflow(load,\n",
    "                          base,\n",
    "                          edges,\n",
    "                          save)\n",
    "\n",
    "executor = EOExecutor(workflow, execution_args)\n",
    "executor.run(multiprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the mask\n",
    "\n",
    "patch_name = next(os.walk(patches_path))[1][0]\n",
    "eopatch = EOPatch.load(f'{save_path}/{patch_name}')\n",
    "\n",
    "edges = eopatch.mask_timeless['EDGES_INV'].squeeze()\n",
    "img = np.clip(eopatch.data['BANDS'][10][..., [3, 2, 1]] * 3.5, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "We don't want to train a classifier on every point as earth observation data can be very large and thus unfeasible. In this step we will choose a sample of the area. The properties of a sample should be that it is taken from all region uniformly and because we are training a classifier we want to have each class represented equally. This can be done with the BalancedClassSampler task. We will also exclude the the edge regions we calculated before to have a \"clean\" sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feature = (FeatureType.MASK_TIMELESS, 'LPIS_2017')\n",
    "sampler = BalancedClassSampler(class_feature=class_feature,\n",
    "                               valid_mask=(FeatureType.MASK_TIMELESS, 'EDGES_INV'),\n",
    "                               seed=seed)\n",
    "sampler.sample_folder(save_path, lazy_loading=True)\n",
    "distribution = sampler.get_prior_class_distribution()\n",
    "\n",
    "# sorting so we can easier see which classes are less represented\n",
    "distribution = {k: v for k, v in sorted(distribution.items(), key=lambda item: item[1])}\n",
    "\n",
    "# Lets display what was sampled\n",
    "print(distribution)\n",
    "\n",
    "# We can try to increase the smallest samples classes by sampling again and this time specifying which classes\n",
    "# are weak to do additional sampling around them once encountered\n",
    "sampler2 = BalancedClassSampler(class_feature=class_feature,\n",
    "                               valid_mask=(FeatureType.MASK_TIMELESS, 'EDGES_INV'),\n",
    "                               seed=seed,\n",
    "                               weak_classes=[6, 7, 5, 3])\n",
    "sampler2.sample_folder(save_path, lazy_loading=True)\n",
    "distribution2 = sampler2.get_prior_class_distribution()\n",
    "distribution2 = {k: v for k, v in sorted(distribution2.items(), key=lambda item: item[1])}\n",
    "print(distribution2)\n",
    "\n",
    "# Final samples\n",
    "samples = sampler2.get_balanced_data()\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream features calculation\n",
    "As we didn't have stream features calculated for all data we will now compute neccesary stream features for only the points that we decided on with sampling in previous step.\n",
    "We will also add height of the pixel as one of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes all the patches have same shape\n",
    "height, width, _ = eopatch[class_feature].shape\n",
    "\n",
    "# For each patch that contains any samples we will construct mask to specify where the stream\n",
    "# features are computer. We don't want to compute them for the whole patch as it would take a long time\n",
    "patches = next(os.walk(patches_path))[1]\n",
    "\n",
    "# Separate points by patch. Patch identifier is by default it's folder name\n",
    "separated_by_patch = [(x, samples[samples['patch_identifier'] == x]) for x in patches]\n",
    "execution_args = []\n",
    "for name, points in separated_by_patch:\n",
    "    eopatch = EOPatch.load(f'{save_path}/{name}')\n",
    "    stream_mask = np.zeros((width, height))\n",
    "    for x, y in zip(points['x'], points['y']):\n",
    "        stream_mask[x, y] = True\n",
    "    eopatch.add_feature(FeatureType.MASK_TIMELESS, 'STREAM_VALID', stream_mask[..., np.newaxis])\n",
    "    eopatch.save(f'{save_path}/{name}', eopatch, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TODO Filip\n",
    "# Skopiraj kodo ko bo v `notebook_temporary` folder\n",
    "spatio_temporal = AddSpatioTemporalFeaturesTask()\n",
    "max_mean_len = MaxMeanLenTask()\n",
    "surface_extraction = SurfaceExtractionTask()\n",
    "max_min_temporal = AddMaxMinTemporalIndicesTask()\n",
    "max_min_ndvi_slope = AddMaxMinNDVISlopeIndicesTask()\n",
    "all_stream_feature_names = []  # 'NDVI_max_mean', 'NDVI_slope' .....\n",
    "##### TODO Filip\n",
    "\n",
    "execution_args = []\n",
    "for name in next(os.walk(patches_path))[1]:\n",
    "    execution_args.append({\n",
    "        load: {'eopatch_folder': name},\n",
    "        save: {'eopatch_folder': name}\n",
    "    })\n",
    "    \n",
    "# This tasks adds elevation data to the patch\n",
    "dem = SentinelHubDemTask((FeatureType.DATA_TIMELESS, 'DEM'), size=(height, width))\n",
    "workflow = LinearWorkflow(load,\n",
    "                          dem,\n",
    "                          spatio_temporal,\n",
    "                          max_mean_len,\n",
    "                          surface_extraction,\n",
    "                          max_min_temporal,\n",
    "                          max_min_ndvi_slope,\n",
    "                          save)\n",
    "executor = EOExecutor(workflow, execution_args)\n",
    "executor.run(multiprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the stream features are calculated we just need to put them into the format suitable for feature selection\n",
    "# we need to contruct a pandas DataFrame with column names of features and the class name. Each row represents a single point\n",
    "extended_samples = []\n",
    "for name, points in separated_by_patch:\n",
    "    eopatch = EOPatch.load(f'{save_path}/{name}', lazy_loading=True)\n",
    "    for x, y in zip(points['x'], points['y']):\n",
    "        point_data = [(class_feature[1], eopatch[class_feature][x, y, 0])] \\\n",
    "                     + [(f, eopatch.data_timeless[f][x, y].squeeze()) for f in all_stream_feature_names]\n",
    "        extended_samples.append(dict(point_data))\n",
    "extended_samples = pd.DataFrame(extended_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and model construction\n",
    "The features will be chosen using the FASTENER algorithm\n",
    "## TODO filip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = FASTENER(extended_samples) ###### TODO FILIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction\n",
    "Once we have final samples with selected only the best features we can train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = tree.DecisionTreeClassifier()\n",
    "    y = extended_samples['LPIS_2017'].to_numpy()\n",
    "    x = extended_samples[selected_features].to_numpy()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "    sc = StandardScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    labels = Counter(extended_samples['LPIS_2017']).keys()\n",
    "    no_classes = range(len(labels))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylim(bottom=0.14, top=0)\n",
    "    plot_confusion_matrix(model, x_test, y_test, labels=no_classes,\n",
    "                          display_labels=labels,\n",
    "                          cmap='viridis',\n",
    "                          include_values=False,\n",
    "                          xticks_rotation='vertical',\n",
    "                          normalize='pred',\n",
    "                          ax=ax)\n",
    "    f1 = f1_score(y_test, y_pred, labels=no_classes, average='macro')\n",
    "    print(f'f1: {f1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model usage on a sample region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
