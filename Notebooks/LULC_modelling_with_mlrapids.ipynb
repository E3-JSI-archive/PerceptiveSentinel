{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitlulcconda51eeda4f822c430d91c431c592064ade",
   "display_name": "Python 3.7.6 64-bit ('lulc': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Use/Land Cover (LULC) modelling with `ml-rapids` and `eo-learn`\n",
    "\n",
    "## `ml-rapids`\n",
    "- implementaion of incremental algorithms in C++\n",
    "- bindings for Python\n",
    "- implements scikit-learn's incremental learner interface (`fit`, `predict`)\n",
    "- Classification methods:\n",
    "    - Majority Class\n",
    "    - Naive Bayes\n",
    "    - Logistic Regression\n",
    "    - Perceptron\n",
    "    - VFDT (Very Fast Decision Trees) aka Hoeffding Trees\n",
    "    - HAT (Hoeffding Adaptive Trees)\n",
    "    - Bagging\n",
    "\n",
    "- GitHub repository: [https://github.com/JozefStefanInstitute/ml-rapids](https://github.com/JozefStefanInstitute/ml-rapids)\n",
    "- Install with package installer for Python ([https://pypi.org/project/ml-rapids/](https://pypi.org/project/ml-rapids/)):\n",
    "\n",
    "`pip install ml_rapids`\n",
    "\n",
    "- Future plans:\n",
    "    - Improved Python support (pickling of models)\n",
    "    - Additional methods\n",
    "    - Regression methods\n",
    "    - JavaScript bindings (npm package)\n",
    "\n",
    "## Demo\n",
    "- Land Use/Land Cover (LULC) modelling using `ml-rapids` and `eo-learn`\n",
    "- We compare methods from 3 different libraries (2 batch learning methods, 1 incremental learning method):\n",
    "    - `LGBMClassifier`: Light Gradinet Boosting Machine from [https://github.com/microsoft/LightGBM](https://github.com/microsoft/LightGBM) (batch)\n",
    "    - `RandomForestClassifier`: Random Forest Classifier from [https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn) (batch)\n",
    "    - `HoeffdingTree`: Hoeffding Tree Classifier from [https://github.com/JozefStefanInstitute/ml-rapids](https://github.com/JozefStefanInstitute/ml-rapids) (incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup juptyer notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import all dependencies\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import sklearn\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from eolearn.core import EOExecutor, EOPatch, EOTask, FeatureType, \\\n",
    "    LinearWorkflow, LoadTask, SaveTask, OverwritePermission\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, \\\n",
    "    f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, \\\n",
    "    KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from notebook_temporary.features import AddStreamTemporalFeaturesTask\n",
    "from notebook_temporary.tasks import PredictPatch\n",
    "from notebook_temporary.utilities import get_eopatch_ids, plot_grid, plot_roi, \\\n",
    "    img_rgb, img_feature, img_diff, abbreviate, plot_features, plot_confusion_matrix, \\\n",
    "    evaluate_grid\n",
    "\n",
    "# Machine learning algorithms\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ml_rapids import HoeffdingTree\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "EO data:\n",
    "- Slovenia split into 1085 patches ([plot](#))\n",
    "- each patch with resolution 505x500 pixels (10m/px)\n",
    "- Sentinel 2 (L1C), 2017, 13 bands (cca. 1TB)\n",
    "\n",
    "LULC (ground truth):\n",
    "- [https://rkg.gov.si/](https://rkg.gov.si/) (Ministry for agriculture, forestry and food)\n",
    "- Originally 25 classes, grouped into 10 classes\n",
    "\n",
    "Preparation:\n",
    "- cloud detection and masking\n",
    "- interpolation of missing values\n",
    "- edge detection and masking\n",
    "- sampling, balancing\n",
    "- feature calculation (base features, stream features)\n",
    "- elevation, inclination\n",
    "- grouping and rasterication of LULC\n",
    "- feature selection\n",
    "\n",
    "Dataset:\n",
    "- balanced: 50000 samples/class\n",
    "- 8 classes (2 not present)\n",
    "- total: 4000000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original LULC classes\n",
    "# 0\t\t        No Data\n",
    "# 1\t    1100\tArable land\n",
    "# 2\t    1160\tHop field\n",
    "# 3\t    1180\tPermanent crops on arable land\n",
    "# 4\t    1190\tGreenhouse\n",
    "# 5\t    1211\tVineyard\n",
    "# 6\t    1212\tNursery\n",
    "# 7\t    1221\tIntensive orchard\n",
    "# 8\t    1222\tExtensive orchard\n",
    "# 9\t    1230\tOlive grove\n",
    "# 10\t1240\tOther permanent crop\n",
    "# 11\t1300\tPermanent grassland\n",
    "# 12\t1321\tSwampy meadow\n",
    "# 13\t1410\tOvergrown agricultural area\n",
    "# 14\t1420\tForest plantation\n",
    "# 15\t1500\tTrees and shrubs\n",
    "# 16\t1600\tUncultivated agricultural land\n",
    "# 17\t1800\tForest trees on agricultural land\n",
    "# 18\t2000\tForest\n",
    "# 19\t3000\tBuilt-up area and related surface\n",
    "# 20\t4100\tSwamp\n",
    "# 21\t4210\tReed\n",
    "# 22\t4220\tOther marshy area\n",
    "# 23\t5000\tDried open area with special vegetation\n",
    "# 24\t6000\tOpen area with little or no vegetation\n",
    "# 25\t7000\tWater\n",
    "\n",
    "LULC_G = [\n",
    "    ('No Data',            '#000000'), # 1600\n",
    "    ('Cultivated Land',    '#ffa500'), # 1100, 1160, 1180, 1190, 1211, 1212, 1221, 1222, 1230, 1240\n",
    "    ('Forest',             '#054907'), # 1420, 2000\n",
    "    ('Grassland',          '#aaff32'), # 1300, 1321, 1800\n",
    "    ('Shrubland',          '#806000'), # 1410, 1500, 5000\n",
    "    ('Water',              '#069af3'), # 7000\n",
    "    ('Wetlands',           '#95d0fc'), # 4100, 4210, 4220\n",
    "    ('Tundra',             '#967bb6'), #\n",
    "    ('Artificial Surface', '#dc143c'), # 3000\n",
    "    ('Bareland',           '#a6a6a6'), # 6000\n",
    "    ('Snow and Ice',       '#ffffff'), #\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "country = gpd.read_file(os.path.join('data', 'SVN', 'shape', 'country.shp'))\n",
    "country_grid = gpd.read_file(os.path.join('data', 'SVN', 'shape', 'grid.shp'))\n",
    "\n",
    "plot_roi(\n",
    "    country,\n",
    "    country_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load the sampled dataset from CSV file:\n",
    "dataset_path = os.path.join(os.getcwd(), 'data', 'SVN', '2017', 'samples')\n",
    "dataset = pd.read_csv(os.path.join(dataset_path, 'dataset.csv'))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the list of features selected by FASTENER (200 generations) from CSV file\n",
    "selected_features = list(pd.read_csv(os.path.join(dataset_path, 'features.csv')).columns)\n",
    "\n",
    "print(f'Selected features ({len(selected_features)} / {len(dataset.columns[4:])}):')\n",
    "for feature in selected_features:\n",
    "    print(f'- {feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare input and target values for ML algorithms from selected features\n",
    "X = dataset[selected_features].to_numpy()\n",
    "y = dataset['LULC_G'].to_numpy()\n",
    "\n",
    "labels_unique = np.unique(y)\n",
    "num_classes = len(labels_unique)\n",
    "\n",
    "# Normalize input values\n",
    "# X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "We evaluate models with 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure ML methods\n",
    "methods = [\n",
    "    (LGBMClassifier, {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class': num_classes,\n",
    "        'random_state': 42\n",
    "    }),\n",
    "    (RandomForestClassifier, {\n",
    "        'n_estimators': 10,\n",
    "        'max_depth': None,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'random_state': 42\n",
    "    }),\n",
    "    (HoeffdingTree, {\n",
    "        'max_byte_size': 33554432,\n",
    "        'memory_estimate_period': 1000000,\n",
    "        'grace_period': 200,\n",
    "        'split_confidence': 0.0000001,\n",
    "        'tie_threshold': 0.5,\n",
    "        'binary_splits': False,\n",
    "        'stop_mem_management': False,\n",
    "        'remove_poor_atts': False,\n",
    "        'leaf_learner': 'NBAdaptive',\n",
    "        'nb_threshold': 0,\n",
    "        'tree_property_index_list': '',\n",
    "        'no_pre_prune': False\n",
    "    })\n",
    "]\n",
    "\n",
    "# Initialize evaluation report table\n",
    "report = pd.DataFrame(\n",
    "    { k: np.zeros(len(methods)) for k in ['Training time', 'Inference time', 'CA', 'F1'] },\n",
    "    index=[method[0].__name__ for method in methods]\n",
    ")\n",
    "\n",
    "y_shuffled = []\n",
    "y_shuffled_pred = { method[0].__name__: [] for method in methods }\n",
    "\n",
    "# Evaluate with 5-fold cross validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=42, shuffle=True)\n",
    "pbar = tqdm(total=k*len(methods))\n",
    "for cv, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_shuffled += list(y_test)\n",
    "\n",
    "    for method in methods:\n",
    "        # Initialize model\n",
    "        method_name = method[0].__name__\n",
    "        model = method[0](**method[1])\n",
    "\n",
    "        # Train model on training set\n",
    "        training_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = time.time() - training_time\n",
    "        report.loc[method_name, 'Training time'] += training_time / k\n",
    "\n",
    "        # Predict classes on test set\n",
    "        inference_time = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        inference_time = time.time() - inference_time\n",
    "        report.loc[method_name, 'Inference time'] += inference_time / k\n",
    "\n",
    "        y_shuffled_pred[method_name] += list(y_pred)\n",
    "\n",
    "        # Calulate average classification accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report.loc[method_name, 'CA'] += accuracy / k\n",
    "        \n",
    "        # Calculate average F1 score\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        report.loc[method_name, 'F1'] += f1 / k\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update()\n",
    "\n",
    "# Show evaluation report\n",
    "report.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot confusion metrices\n",
    "for method in methods:\n",
    "    plot_confusion_matrix(\n",
    "        np.array(y_shuffled) - 1,\n",
    "        np.array(y_shuffled_pred[method[0].__name__]) - 1,\n",
    "        [l[0] for l in LULC_G[1:]],\n",
    "        title=f'Confusion matrix ({method[0].__name__})'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Next we build models with selected methods on the whole dataset and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select methods\n",
    "selected_methods = [\n",
    "    LGBMClassifier,\n",
    "    RandomForestClassifier,\n",
    "    HoeffdingTree\n",
    "]\n",
    "\n",
    "models_path = os.path.join(os.getcwd(), 'models', 'LULC', '2017')\n",
    "if not os.path.isdir(models_path):\n",
    "    os.makedirs(models_path)\n",
    "\n",
    "models = []\n",
    "for method in tqdm([m for m in methods if m[0] in selected_methods]):\n",
    "    # Initialize model\n",
    "    model = method[0](**method[1])\n",
    "    model_name = method[0].__name__\n",
    "\n",
    "    # Train the model on whole dataset\n",
    "    model.fit(X, y)\n",
    "    models.append(model)\n",
    "\n",
    "    # Save the model for later use\n",
    "    if hasattr(model, 'export_json'):\n",
    "        # ml-rapids models are exported to JSON\n",
    "        model_path = os.path.join(models_path, f'{model_name}.json')\n",
    "        model.export_json(model_path)\n",
    "    else:\n",
    "        # Other models are pickled\n",
    "        model_path = os.path.join(models_path, f'{model_name}.pkl')\n",
    "        joblib.dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model usage on selected region\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define ROI\n",
    "# country = gpd.read_file(os.path.join('data', 'SVN', 'shape', 'country.shp'))\n",
    "# country_grid = gpd.read_file(os.path.join('data', 'SVN', 'shape', 'grid.shp'))\n",
    "eopatch_root_path = os.path.join(os.getcwd(), 'data', 'SVN', '2017', 'patches')\n",
    "eopatch_ids = get_eopatch_ids(395, 466, country_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot ROI\n",
    "plot_roi(\n",
    "    country,\n",
    "    country_grid,\n",
    "    eopatch_ids=eopatch_ids,\n",
    "    title='Ljubljana, Slovenia',\n",
    "    size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot RGB\n",
    "plot_grid(\n",
    "    eopatch_ids,\n",
    "    eopatch_root_path,\n",
    "    img_rgb,\n",
    "    img_func_args={\n",
    "        'date': '2017-07-01'\n",
    "    },\n",
    "    title='Ljubljana, Slovenia (RGB)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate selected features\n",
    "\n",
    "Here we calculate selected features for 16 eopatches from our region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define tasks\n",
    "tasks = []\n",
    "\n",
    "# 1. Load Task\n",
    "tasks.append(LoadTask(\n",
    "    eopatch_root_path,\n",
    "    lazy_loading=True\n",
    "))\n",
    "\n",
    "# Parse selected features\n",
    "data_features = {}\n",
    "feature_names = []\n",
    "for feature in selected_features:\n",
    "    tokens = feature.split('_')\n",
    "    if len(tokens) > 1:\n",
    "        if tokens[0] not in data_features:\n",
    "            data_features[tokens[0]] = []\n",
    "        data_features[tokens[0]].append('_'.join(tokens[1:]))\n",
    "        feature_names.append(feature)\n",
    "\n",
    "# 2. Add Stream Features Task\n",
    "for base_feature, stream_features in data_features.items():\n",
    "    if stream_features:\n",
    "        tasks.append(\n",
    "            AddStreamTemporalFeaturesTask(\n",
    "                data_feature=base_feature,\n",
    "                features=stream_features\n",
    "            )\n",
    "        )\n",
    "\n",
    "# 3. Save Task\n",
    "tasks.append(SaveTask(\n",
    "    eopatch_root_path,\n",
    "    overwrite_permission=OverwritePermission.OVERWRITE_FEATURES,\n",
    "    features=[(FeatureType.DATA_TIMELESS, feature) for feature in feature_names]\n",
    "))\n",
    "\n",
    "workflow = LinearWorkflow(*tasks)\n",
    "workflow.dependency_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define execution arguments\n",
    "execution_args = []\n",
    "task_dict = workflow.get_tasks()\n",
    "\n",
    "for eopatch_id in eopatch_ids.ravel():\n",
    "    eopatch_folder = f'eopatch_{eopatch_id}'\n",
    "    execution_args.append({\n",
    "        task_dict['LoadTask']: {\n",
    "            'eopatch_folder': eopatch_folder\n",
    "        },\n",
    "        task_dict['SaveTask']: {\n",
    "            'eopatch_folder': eopatch_folder\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Execute workflow\n",
    "executor = EOExecutor(\n",
    "    workflow,\n",
    "    execution_args,\n",
    "    save_logs=True,\n",
    "    logs_folder='logs'\n",
    ")\n",
    "executor.run()\n",
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot selected features (for one patch)\n",
    "plot_features(os.path.join(eopatch_root_path, 'eopatch_395'), selected_features, max_cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict LULC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define tasks\n",
    "tasks = []\n",
    "\n",
    "# 1. Load Task\n",
    "tasks.append(LoadTask(\n",
    "    eopatch_root_path,\n",
    "    lazy_loading=True\n",
    "))\n",
    "\n",
    "# Load models\n",
    "models = []\n",
    "for method in selected_methods:\n",
    "    model_name = method.__name__\n",
    "    model_path = os.path.join(models_path, f'{model_name}.pkl')\n",
    "\n",
    "    if os.path.isfile(model_path):\n",
    "        models.append(joblib.load(model_path))\n",
    "    elif hasattr(method, 'import_json'):\n",
    "        model_path = os.path.join(models_path, f'{model_name}.json')\n",
    "        model = method()\n",
    "        model.import_json(model_path)\n",
    "        models.append(model)\n",
    "\n",
    "# 2. Predict Patch Task\n",
    "feature_names = []\n",
    "for model in models:\n",
    "    feature_name = 'LULC_G_PRED_' + abbreviate(type(model).__name__)\n",
    "    feature_names.append(feature_name)\n",
    "    tasks.append(PredictPatch(\n",
    "        model,\n",
    "        selected_features,\n",
    "        feature_name\n",
    "    ))\n",
    "\n",
    "# 3. Save Task\n",
    "tasks.append(SaveTask(\n",
    "    eopatch_root_path,\n",
    "    overwrite_permission=OverwritePermission.OVERWRITE_FEATURES,\n",
    "    features=[(FeatureType.MASK_TIMELESS, feature) for feature in feature_names]\n",
    "))\n",
    "\n",
    "workflow = LinearWorkflow(*tasks)\n",
    "workflow.dependency_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define execution arguments\n",
    "execution_args = []\n",
    "task_dict = workflow.get_tasks()\n",
    "\n",
    "for eopatch_id in eopatch_ids.ravel():\n",
    "    eopatch_folder = f'eopatch_{eopatch_id}'\n",
    "    execution_args.append({\n",
    "        task_dict['LoadTask']: {\n",
    "            'eopatch_folder': eopatch_folder\n",
    "        },\n",
    "        task_dict['SaveTask']: {\n",
    "            'eopatch_folder': eopatch_folder\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Execute workflow\n",
    "executor = EOExecutor(\n",
    "    workflow,\n",
    "    execution_args,\n",
    "    save_logs=True,\n",
    "    logs_folder='logs'\n",
    ")\n",
    "executor.run()\n",
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOPatch example\n",
    "EOPatch.load(os.path.join(eopatch_root_path, 'eopatch_395'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "labels = [c[0] for c in LULC_G]\n",
    "classes = list(range(len(labels)))\n",
    "bounds = np.append(np.array(classes) - 0.5, classes[-1] + 0.5)\n",
    "\n",
    "for mask in ['LULC_G'] + ['LULC_G_PRED_' + abbreviate(type(model).__name__) for model in models]:\n",
    "    plot_grid(\n",
    "        eopatch_ids,\n",
    "        eopatch_root_path,\n",
    "        img_feature,\n",
    "        img_func_args={\n",
    "            'feature': (FeatureType.MASK_TIMELESS, mask)\n",
    "        },\n",
    "        imshow_args={\n",
    "            'cmap': ListedColormap(\n",
    "                [c[1] for c in LULC_G],\n",
    "                name='lulc_map'\n",
    "            ),\n",
    "            'norm': BoundaryNorm(bounds, len(classes))\n",
    "        },\n",
    "        colorbar={\n",
    "            'ticks': classes,\n",
    "            'labels': labels\n",
    "        },\n",
    "        title=mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}